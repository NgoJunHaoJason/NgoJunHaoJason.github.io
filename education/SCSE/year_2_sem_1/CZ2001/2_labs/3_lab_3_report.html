<!DOCTYPE html>

<html>
<!--remember to include the following for mobile-->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<head>
    <title>CZ2001 Lab 3 Report | Jason Ngo's website</title>
    <link rel="icon" href="../../../../../images/sciurus_96.png">
    <link rel="stylesheet" type="text/css" href="../../../../../styles/default_style.css">
</head>

<body>
    <h2 class="header">
        CZ2001 Algorithms
    </h2>

    <!--start of nav-related code-->
    <ul class="navbar">
        <li>
            <a href="../../../../../index.html">
                home
            </a>
        </li>

        <li>
            <a href="../../../../main.html">
                education
            </a>
        </li>

        <li>
            <a href="../../../../../experience.html">
                experience
            </a>
        </li>

        <li>
            <a href="../../../../../miscellaneous/main.html">
                miscellaneous
            </a>
        </li>
    </ul>
    <!--end of nav-related code-->

    <!--start of content-related code-->
    <div class="content">
        <h3>Example Class 3 Report (Project 3A)</h3>

        <p><u>Full Algorithmic Implementation</u></p>

        <p>
            <b>Insertion sort</b> in its entirety is adding a number in an already sorted array. This is achieved by
            arranging two 2 key values first and then repeating the process for the rest of the array. The insertion
            sort algorithm we used works by comparing each key (of index <i>i</i>) in the input array against the key
            that comes before it (index <i>i</i>-1).
        </p>

        <p>
            If the key at index <i>i</i> is smaller than the one at index <i>i</i>-1, these 2 keys would swap positions,
            such the key previously at index <i>i</i> is now at index <i>i</i>-1, and vice versa. They would continue to
            swap positions, until there are no more keys in front of it (i.e. the ith key is the first key of the array)
            or the key before it is smaller, as the array has already been sorted. Thus an array in ascending order is
            obtained.
        </p>

        <p>
            <b>Merge sort</b> works by using the divide-and-conquer strategy. if the input array has a size of 1 or
            less, it is considered trivially sorted; otherwise, the input array will be split evenly into two subarrays
            and have merge sort performed on them, after which the two sorted subarrays are joined using the merge
            function to obtain an array of the original size, sorted in order.
        </p>

        <p>
            Also, if one of the subarrays still has keys when the other subarray is exhausted, the remaining keys would
            be merged directly into the auxiliary array without comparison; and if there are 2 keys that are equal in
            value on separate subarrays, they would be merged together, which means one less key comparison. This case
            does not occur in our program as the input arrays used hold unique integers.
        </p>

        <p>
            <b>Generating Input Data:</b> The input data used are arrays of unique integers, from 1 to <i>n</i>, where
            <i>n</i> is the size of the arrays. The array sizes used range from 1000 to 50 000, with step size of 1000.
            For each array size, ascending, descending and randomly ordered arrays are generated: arrays of ascending
            and descending order are generated using simple for-loops where each key’s value correspond to its index in
            the array; and arrays of random order are generated using the Fisher-Yates shuffle algorithm, where for an
            input array, a random number <i>k</i> between 0 and the number of keys yet to be shifted is generated, and
            shifted
            to the end of an output array.
        </p>

        <p>
            <b>Measuring Time Complexity:</b> For each array type and size, we did 60 insertion and merge sorts, and
            counted the number of key comparisons as well as the the CPU time. The dataset is then trimmed to obtain the
            interquartile mean. These statistical results obtained are the empirical results.
        </p>

        <p>
            <u>
                Theoretical Analysis of the Time Complexity of Insertion Sort with Empirical Results:
            </u>
        </p>

        <p>
            <b>1. Best Case [ <mark><i>n</i>-1 = O(<i>n</i>)</mark> ]</b>
        </p>
        <p>
            The best case for insertion sort occurs when the array is already sorted in the desired order. In this case,
            each key in the array, except for the first key, only needs to be compared to the key right before it. So
            for an array of length <i>n</i>, only <i>n</i>-1 number of key comparisons need to be made, resulting in a
            time complexity of O(<i>n</i>).
        </p>

        <p>
            <b>2. Worst Case [ <mark><i>n</i>*(<i>n</i>-1) /2 = O(<i>n</i><sup>2</sup>)</mark> ]</b>
        </p>
        <p>
            The worst case for insertion sort occurs when the array is already sorted, but in the reverse order. In this
            case, each key in the array, except for the 1st key, needs to be compared to all the keys that come before
            it.
        </p>
        <p>
            For a key at index <i>i</i>, there are i-1 keys before it, so it has to go through i-1 number of key
            comparisons. If there are <i>n</i> number of keys in the array (i.e. array of size <i>n</i>), there will be
            <mark>(<i>n</i>-1) + (<i>n</i>-2) + … + 2 + 1 = (<i>n</i>*(<i>n</i>-1) /2)</mark> number of key comparisons
            when sorting
            through this array, resulting in a time complexity of O(<i>n</i><sup>2</sup>).
        </p>

        <p>
            <b>
                3. Average Case [ <mark>(<i>n</i>-1)*(<i>n</i>+2) /4 = O(<i>n</i><sup>2</sup>)</mark> ]
            </b>
        </p>

        <p>
            The average case for insertion sort occurs when the keys in the array are in a completely random order. For
            each key in a randomly-ordered array, there is an equal probability of a key at a particular index being
            compared to each key that comes before it, because there is an equal probability of that particular key
            being smaller or larger than the key that is in front (ie ½) . Mathematically, this means that for each key
            at index <i>i</i> in the array, there is a 1/i chance of it being compared to each key at index 0 through
            i-1, with 1 comparison at each index.
        </p>

        <p>
            So, on average, a key at index <i>i</i> goes through <mark>(1/i)(1+2+...+i) = (1/i)( i*(i+1)/2 ) =
                (i+1)/2</mark> number
            of key comparisons.
        </p>

        <p>
            For an array of length <i>n</i>, each key in the array, except for the first key, goes through the above
            process. Therefore, there are <br>
            &nbsp; [( (<i>n</i>-1) + 1 ) /2] + [( (<i>n</i>-2) + 1 ) /2] + … + [( 2+1) /2] + [(1+1) /2]<br>
            = (½)* [( (<i>n</i>-1) + 1 ) + ( (<i>n</i>-2) + 1 ) + … + ( 2+1) + (1+1)]<br>
            = (½)* [ <i>n</i> + (<i>n</i>-1) + … + 3 + 2 ]<br>
            = (½)* [ (<i>n</i>-1)*(<i>n</i>+2) /2 ]<br>
            = (<i>n</i>-1)*(<i>n</i>+2) /4<br>
            number of key comparisons in an array of length <i>n</i>, resulting in a time complexity of
            O(<i>n</i><sup>2</sup>).
        </p>

        <table class="table">
            <tr>
                <th>
                    Ascending Order<br>
                    O(<i>n</i>)
                </th>
                <th>
                    Random Order<br>
                    O(<i>n</i><sup>2</sup>)
                </th>
                <th>
                    Descending Order<br>
                    O(<i>n</i><sup>2</sup>)
                </th>
            </tr>
            <tr>
                <td>
                    <a target="_blank"
                        href="https://public.tableau.com/profile/lee.yi.zhuo#!/vizhome/InsertionSortonAA/Dashboard1?publish=yes">
                        <img data-src="lab_3_images/insertionsort_ascending_scatterplot.png" class="lazy">
                    </a>
                </td>
                <td>
                    <a target="_blank"
                        href="https://public.tableau.com/profile/lee.yi.zhuo#!/vizhome/InsertionSortonRA/Dashboard1?publish=yes">
                        <img data-src="lab_3_images/insertionsort_random_scatterplot.png" class="lazy">
                    </a>
                </td>
                <td>
                    <a target="_blank"
                        href="https://public.tableau.com/profile/lee.yi.zhuo#!/vizhome/InsertionSortonDA/Dashboard1?publish=yes">
                        <img data-src="lab_3_images/insertionsort_descending_scatterplot.png" class="lazy">
                    </a>
                </td>
            </tr>
        </table>

        <p>
            <u>
                Theoretical Analysis of the Time Complexity of Merge Sort
            </u>
        </p>

        <p>
            Merge sort functions by splitting the original array (of length <i>n</i>) into 2 subarrays of equal length
            (<i>n</i>/2), and recursively splits the subarrays till each subarray contains only 1 key. When a subarray
            has a length of 1, it is considered trivially sorted so there is no need for any key comparison. This is the
            base case (<mark>W(1) = 0</mark>) for the recurrence equation which solves the time complexity of merge
            sort..
        </p>

        <p>
            The comparisons of keys in the subarrays are done in the merging of a pair of subarrays that were split from
            an original array. This forms the recurrence equation: <mark>W(<i>n</i>) = 2*W(<i>n</i>/2) + (number of key
                comparisons in the merging of subarrays)</mark> for number of key comparisons for a merge sort on an
            array of
            length <i>n</i>.
        </p>

        <p>
            For an array of length <i>n</i> where <mark><i>n</i> = 2k (<i>k</i> &GreaterEqual; 0)</mark>, there will be
            <i>k</i> number of splits. This is
            because each split results in a subarray of length of <mark><i>n</i>/2 = 2k-1</mark> and every subarray is
            split
            recursively till each of them has a length of <mark>1 = 2<sup>0</sup></mark>. <i>k</i> number of splits
            would result in <i>k</i> number of pairs
            of subarrays, which in turn results in <i>k</i> number of merges. Therefore, the number of merges in a merge
            sort
            on an array of length <i>n</i> is <mark><i>k</i> = log<sub>2</sub> <i>n</i></mark>.
        </p>

        <p>
            The number of key comparisons in a merge of 2 subarrays varies, case-dependent.
        </p>

        <p>
            <b>
                1. Best Case [ <mark>(<i>n</i>/2)*log<sub>2</sub> <i>n</i> = O( <i>n</i>*(lg <i>n</i>) )</mark> ]
            </b>
        </p>

        <p>
            The best case for merge sort occurs when every key in one subarray are smaller than or equal to every key in
            the other subarray. Each key of the first subarray will be compared against the first (smallest) key of the
            second subarray. After comparing and finding that the last (biggest) key of the first subarray is smaller
            than the first (smallest) key of the second subarray, the rest of the keys in the second subarray are
            assumed to be bigger than all the keys in the first subarray, and are merged without a need for comparison.
        </p>

        <p>
            As such, the number of key comparisons in this case is the length of the first subarray. If the original
            array is of length <i>n</i> and the recursive splitting is such that 2 subarrays resulting from the split
            are of approximately equal length, then the length of the first subarray is <i>n</i>/2. This means
            <i>n</i>/2 number of key comparisons for each merge, so there are <i>n</i>/2 number of key comparisons.
        </p>

        <p>
            The best case can also occur when each key at index <i>i</i> in the first subarray is equal to each key at
            index <i>i</i> in the second subarray, in which case both keys are merged simultaneously. When the keys from
            both subarrays are all merged pair-wise, simultaneously, the number of key comparisons is equal to the
            number of keys in either subarray (i.e. length of subarray) which is also <i>n</i>/2.
        </p>

        <p>
            Therefore, the number of key comparisons is given by the recurrence equation:<br>
            &nbsp; W(<i>n</i>) = 2*W(<i>n</i>/2) + <i>n</i>/2, or<br>
            &nbsp; W(2k) = 2* W(2k-1) + 2k-1<br>
            = 2*( 2*W(2k-2) + 2k-2 ) + 2k-1<br>
            ...<br>
            = 2k * W(1) + <i>k</i> * ( 2k-1 )<br>
            = 0 + (log<sub>2</sub> <i>n</i>) * <i>n</i> / 2<br>
        </p>

        <p>
            After simplification, this gives us a time complexity of O( <i>n</i> * lg <i>n</i> ).
        </p>

        <p>
            <b>
                2. Worst Case [ <mark><i>n</i>*log<sub>2</sub> <i>n</i> - <i>n</i> + 1 = O( <i>n</i>*(lg <i>n</i>)
                    )</mark> ]
            </b>
        </p>

        <p>
            The worst case occurs when the largest and second largest keys among both subarrays are in separate
            subarrays or, if there are two keys with the largest value, each of these keys are in separate subarrays.
        </p>

        <p>
            This arrangement is such that all keys up to the largest keys in each subarray of length <i>n</i>/2 have to
            be compared to another key. The largest keys in both subarrays would be compared against each other before
            being merged simultaneously. As such, the number of comparisons in one merge is <mark><i>n</i>/2 +
                <i>n</i>/2 - 1
                = <i>n</i>-1</mark>. Note that the number of key comparisons is one less than the total length of the
            subarrays as
            the last keys of both subarrays are merged together.
        </p>

        <p>
            Therefore, the number of key comparisons is given by the recurrence equation:<br>
            &nbsp; W(<i>n</i>) = 2* W(<i>n</i>/2) + (<i>n</i>-1), or<br>
            &nbsp; W(2k) = 2* W(2k-1) + (2k - 1)<br>
            = 2* [ 2* W(2k-2) + (2k-1 - 1) ] + (2k - 1)<br>
            = 22 * W(2k-2) + (2k - 2) + (2k - 1)<br>
            = 23 * W(2k-3) + (2k - 22) + (2k - 21) + (2k - 20)<br>
            …<br>
            = 2k * W(2k-<i>k</i>) + <i>k</i> * 2k - ( 2k-1 + … + 22 + 21 + 20 )<br>
            = 2k * W(1) + (log<sub>2</sub> <i>n</i>) * <i>n</i> - ( 2k -1 )<br>
            = 0 + (log<sub>2</sub> <i>n</i>) * <i>n</i> - <i>n</i> + 1<br>
        </p>

        <p>
            After simplification, this gives us a time complexity of O( <i>n</i> * lg <i>n</i> )
        </p>

        <p>
            <b>
                3. Average Case [ c1*<i>n</i>*log<sub>2</sub> <i>n</i> + c2*<i>n</i> + c3 = O(<i>n</i>*(lg <i>n</i>) ]
            </b>
        </p>

        <p>
            The average case for merge sort occurs when keys of the input array are randomly-ordered, such that each key
            is equally likely to be in any position in the array. In the average case, the probability of a key in the
            first subarray having to be compared to a key in the second subarray in each merge has to be taken into
            account when calculating the average total number of key comparisons in merge sort.
        </p>

        <p>
            Based on the best case and worst case of merge sort, we know that the number of key comparisons in a merge
            must be between <i>n</i>/2 and <i>n</i>-1, inclusive. That is, the possible numbers of key comparisons forms
            the sequence {<i>n</i>/2, <i>n</i>/2 + 1, …, <i>n</i>-2, <i>n</i>-1}.
        </p>

        <p>
            Merging takes <i>n</i>-1 number of key comparisons (also the worst case) when one subarray has the largest
            key, while the other has the second largest key. This results in 2 combinations of (<i>n</i>-2)!
            permutations of subarrays (i.e. 2*(<i>n</i>-2)! permutations).
        </p>

        <p>
            Merging takes <i>n</i>-2 number of key comparisons when one subarray has the largest 2 keys, while the other
            has the third largest key. This results in 2 combinations of (<i>n</i>-3)! permutations of subarrays (i.e.
            2*(<i>n</i>-3)! permutations).
        </p>

        <p>
            Merging takes <i>n</i>-3 number of key comparisons when one subarray has the largest 3 keys, while the other
            has the fourth largest key. This results in 2 combinations of (<i>n</i>-4)! permutations of subarrays (i.e.
            2*(<i>n</i>-4)! permutations).
        </p>

        <p> ...</p>

        <p>
            Merging takes <i>n</i>-(<i>n</i>/2 - 1) number of key comparisons when one subarray has the largest
            <i>n</i>/2 - 1 keys, while the other has the (<i>n</i>/2)th largest key (ie one subarray has all but the
            smallest larger keys, while the other subarray has all but the largest smaller keys). This results in 2
            combinations of <mark>(<i>n</i> - (<i>n</i>/2 - 1+1))! = (<i>n</i>/2)!</mark>
            permutations of subarrays (i.e. 2*(<i>n</i>/2)! permutations).
        </p>

        <p>
            In general, merging takes <i>n</i>-j number of key comparisons when one subarray has the largest j keys,
            while the other has the (j+1)th largest key. This results in 2 combinations of (n−j+1)! permutations of
            subarrays (i.e. 2*(n−j+1)! permutations).
        </p>

        <p>
            The general term for number of combinations for a particular number of key comparisons does not apply to
            <i>n</i>/2 number of key comparisons (also the best case). <i>n</i>/2 number of key comparisons has only 2
            combinations: the first subarray contains all the smaller keys, while the second subarray contains all the
            larger keys, and vice versa.
        </p>

        <p>
            As such, the probability for merging requiring a particular number of key comparisons is given by:<br>
            &nbsp; P(<i>n</i>-j)<br>
            = (number of permutations of subarrays that can result in that number of key comparisons) /
            (total number of possible permutations of subarrays)<br>
            = 2*(n−j+1)! / ( 2*(<i>n</i>-2)! + 2*(<i>n</i>-3)! + … + 2*(<i>n</i>/2)! + 2)
        </p>

        <p>
            After obtaining the above probability, the average number of key comparisons in one merge is given by: sum
            of ( (<i>n</i>-j) * P(<i>n</i>-j) ). The number of key comparisons required in for merge sort on average can
            thus be obtained by solving the recurrence equation:<br>
            W(1) = 0<br>
            W(<i>n</i>) = 2*W(<i>n</i>/2) + (average number of key comparisons in one merge of subarrays of size
            <i>n</i>/2)
        </p>

        <p>
            The result should be in the order of <mark>c<sub>1</sub>*<i>n</i> *(log<sub>2</sub> <i>n</i>) -
                c<sub>2</sub>*<i>n</i> + c<sub>3</sub> = O(
                <i>n</i> * lg <i>n</i> )</mark> which closely corresponds to the
            the average number of key comparisons shown on page 43 of (Vitter and Flajolet, 1990).
        </p>

        <p>
            Alternatively, the order of time complexity for the average case of merge sort is the upper-bounded by the
            worst case ( O( (<i>n</i>*log<sub>2</sub> <i>n</i>) - <i>n</i> + 1 ) ) and lower-bounded by the best case (
            &Omega;(
            (<i>n</i>/2)*log<sub>2</sub> <i>n</i> ) ), so it is in the tight
            bound of θ(<i>n</i> * lg <i>n</i>).
        </p>

        <table class="table">
            <tr>
                <th>
                    Ascending Order<br>
                    O(<i>n</i> log <i>n</i>)
                </th>
                <th>
                    Random Order<br>
                    O(<i>n</i> log <i>n</i>)
                </th>
                <th>
                    Descending Order<br>
                    O(<i>n</i> log <i>n</i>)
                </th>
            </tr>
            <tr>
                <td>
                    <a target="_blank"
                        href="https://public.tableau.com/profile/lee.yi.zhuo#!/vizhome/MergeSortonAA/Dashboard1?publish=yes">
                        <img data-src="lab_3_images/mergesort_ascending_scatterplot.png" class="lazy">
                    </a>
                </td>
                <td>
                    <a target="_blank"
                        href="https://public.tableau.com/profile/lee.yi.zhuo#!/vizhome/MergeSortonRA/Dashboard1?publish=yes">
                        <img data-src="lab_3_images/mergesort_random_scatterplot.png" class="lazy">
                    </a>
                </td>
                <td>
                    <a target="_blank"
                        href="https://public.tableau.com/profile/lee.yi.zhuo#!/vizhome/MergeSortonDA/Dashboard1?publish=yes">
                        <img data-src="lab_3_images/mergesort_descending_scatterplot.png" class="lazy">
                    </a>
                </td>
            </tr>
        </table>

        <p>
            <u>
                Comparison of empirical results with theoretical analysis of time complexity
            </u>
        </p>

        <p>
            With the exception of average case time complexity of merge sort, the empirical results of all cases of both
            sorting algorithms corresponds to the time complexity obtained via theoretical analysis, such that a simple
            substitution of array size into the time complexity equations results in the actual number of key
            comparisons.
        </p>

        <p>
            <u>References</u>
        </p>

        <p>
            Vitter, J. and Flajolet, P. (1990). Average-Case Analysis of Algorithms and Data Structures. [online]
            Algo.inria.fr. Available at:
            <a target="_blank" href="http://algo.inria.fr/flajolet/Publications/ViFl90.pdf">
                http://algo.inria.fr/flajolet/Publications/ViFl90.pdf
            </a>
            [Accessed 6 Oct. 2018]
        </p>

        <table class="table" style="width: auto;">
            <tr>
                <th>Authors - SE1 (Group 2)</th>
            </tr>

            <tr>
                <td>LYZ</td>
                </th>
            </tr>
            <tr>
                <td>Ngo Jun Hao Jason</td>
            </tr>
            <tr>
                <td>TSF</td>
            </tr>
            <tr>
                <td>TYHK</td>
            </tr>
            <tr>
                <td>YHL</td>
            </tr>
        </table>
        <br>
    </div>
    <!--end of content-related code-->

    <!--start of nav-buttons code-->
    <div class="nav-buttons">
        <a href="../main.html">
            back
        </a>
    </div>
    <!--end of nav-buttons code-->

    <!--start of footer-related code-->
    <div class="footer">
        <div class="github">
            <img src="../../../../../images/GitHub-Mark-120px-plus.png">

            <a target="_blank" href="https://github.com/NgoJunHaoJason">
                GitHub profile
            </a>
        </div>

        <div class="last-modified">
            last modified:
            <span id="last_modified">null</span>
        </div>
    </div>
    <!--end of footer-related code-->

    <script defer="defer" src="../../../../../scripts/on_page_load.js"></script>
</body>

</html>